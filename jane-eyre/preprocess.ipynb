{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/noracai/Documents/_coding_projects/IBM-Models/jane-eyre\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir(\"/Users/noracai/Documents/_coding_projects/IBM-Models/jane-eyre\")\n",
    "print(os.getcwd()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gale_church_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gale_church_align(english_sentences, french_sentences, merge_threshold=5):\n",
    "#     \"\"\"\n",
    "#     Aligns English and French sentences using an improved Gale-Church approach.\n",
    "#     - `merge_threshold`: Merges short sentences below this word count.\n",
    "#     - Ensures no blank lines and merges small misaligned fragments.\n",
    "#     \"\"\"\n",
    "#     eng_len = len(english_sentences)\n",
    "#     fr_len = len(french_sentences)\n",
    "\n",
    "#     # Convert sentences to word count lengths\n",
    "#     eng_lengths = np.array([len(sent.split()) for sent in english_sentences])\n",
    "#     fr_lengths = np.array([len(sent.split()) for sent in french_sentences])\n",
    "\n",
    "#     # Create a cost matrix based on word count differences\n",
    "#     cost_matrix = np.abs(eng_lengths[:, None] - fr_lengths[None, :])\n",
    "\n",
    "#     # Initialize DP table (INF for all cells except [0,0])\n",
    "#     dp = np.full((eng_len + 1, fr_len + 1), float('inf'))\n",
    "#     dp[0, 0] = 0\n",
    "\n",
    "#     # Back-pointer matrix for path reconstruction\n",
    "#     backtrace = np.zeros((eng_len + 1, fr_len + 1), dtype=int)\n",
    "\n",
    "#     # Fill DP table using minimal cost merging strategy\n",
    "#     for i in range(eng_len + 1):\n",
    "#         for j in range(fr_len + 1):\n",
    "#             if i > 0 and j > 0:  # Normal 1:1 alignment\n",
    "#                 cost = cost_matrix[i - 1, j - 1]\n",
    "#                 if dp[i - 1, j - 1] + cost < dp[i, j]:\n",
    "#                     dp[i, j] = dp[i - 1, j - 1] + cost\n",
    "#                     backtrace[i, j] = 1  # (1 English -> 1 French)\n",
    "\n",
    "#             if i > 0:  # Merge English sentence\n",
    "#                 cost = cost_matrix[i - 1, max(0, j - 1)] if j > 0 else 0\n",
    "#                 if dp[i - 1, j] + cost < dp[i, j]:\n",
    "#                     dp[i, j] = dp[i - 1, j] + cost\n",
    "#                     backtrace[i, j] = 2  # (1 English -> Multiple French)\n",
    "\n",
    "#             if j > 0:  # Merge French sentence\n",
    "#                 cost = cost_matrix[max(0, i - 1), j - 1] if i > 0 else 0\n",
    "#                 if dp[i, j - 1] + cost < dp[i, j]:\n",
    "#                     dp[i, j] = dp[i, j - 1] + cost\n",
    "#                     backtrace[i, j] = 3  # (Multiple English -> 1 French)\n",
    "\n",
    "#     # Backtrace to reconstruct aligned sentence pairs\n",
    "#     aligned_sentences = []\n",
    "#     i, j = eng_len, fr_len\n",
    "#     eng_buffer, fr_buffer = [], []\n",
    "\n",
    "#     while i > 0 or j > 0:\n",
    "#         if backtrace[i, j] == 1:  # Normal 1:1 alignment\n",
    "#             eng_buffer.append(english_sentences[i - 1])\n",
    "#             fr_buffer.append(french_sentences[j - 1])\n",
    "#             aligned_sentences.append((\" \".join(reversed(eng_buffer)), \" \".join(reversed(fr_buffer))))\n",
    "#             eng_buffer, fr_buffer = [], []  # Reset buffers\n",
    "#             i -= 1\n",
    "#             j -= 1\n",
    "\n",
    "#         elif backtrace[i, j] == 2:  # Merge English sentence\n",
    "#             eng_buffer.append(english_sentences[i - 1])\n",
    "#             i -= 1\n",
    "\n",
    "#         elif backtrace[i, j] == 3:  # Merge French sentence\n",
    "#             fr_buffer.append(french_sentences[j - 1])\n",
    "#             j -= 1\n",
    "\n",
    "#     # Reverse since we constructed it backwards\n",
    "#     aligned_sentences.reverse()\n",
    "\n",
    "#     # **Remove empty sentence pairs to prevent blank lines**\n",
    "#     aligned_sentences = [(e, f) for e, f in aligned_sentences if e.strip() or f.strip()]\n",
    "\n",
    "#     return aligned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Enhanced cleaning function for dialogue handling\"\"\"\n",
    "    # Remove quotation marks\n",
    "    text = re.sub(r'[«»\"\"“”]', '', text)\n",
    "    \n",
    "    # Standardize dialogue formatting - replace dialogue dashes with a marker\n",
    "    text = re.sub(r'\\s*-\\s+', ' ', text)  # Remove \" - \" pattern\n",
    "    text = re.sub(r'^\\s*-\\s+', '', text)  # Remove dash at beginning of text\n",
    "    text = re.sub(r'\\n\\s*-\\s+', '\\n', text)  # Remove dash at beginning of lines\n",
    "    text = re.sub(r'\\s*—\\s+', ' ', text)  # Remove \" - \" pattern\n",
    "    text = re.sub(r'^\\s*—\\s+', '', text)  # Remove dash at beginning of text\n",
    "    text = re.sub(r'\\n\\s*—\\s+', '\\n', text)  # Remove dash at beginning of lines\n",
    "    text = re.sub(r'\\s*–\\s+', ' ', text)  # Remove \" - \" pattern\n",
    "    text = re.sub(r'^\\s*–\\s+', '', text)  # Remove dash at beginning of text\n",
    "    text = re.sub(r'\\n\\s*–\\s+', '\\n', text)  # Remove dash at beginning of lines\n",
    "    text = re.sub(r'_(\\w+)_', r'\\1', text)\n",
    "\n",
    "    text = re.sub(r'\\s+([?!;:])', r'\\1', text)\n",
    "    # Remove parenthetical comments which often appear in one language but not the other\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    \n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    abbreviations = {\"Mr.\", \"Mrs.\", \"Ms.\", \"Dr.\", \"Jr.\", \"Sr.\", \"St.\", \"Prof.\", \"Capt.\", \"Lt.\", \"Col.\", \"Gen.\", \"Sgt.\", \"Mt.\", \"M.\", \"Sr.\"}\n",
    "\n",
    "    merged_sentences = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Handle abbreviation cases\n",
    "        if buffer:\n",
    "            sentence = buffer + \" \" + sentence\n",
    "            buffer = \"\"\n",
    "\n",
    "        if any(sentence.endswith(abbr) for abbr in abbreviations):\n",
    "            buffer = sentence  # Hold onto this part to merge with the next\n",
    "            continue\n",
    "\n",
    "        # Remove em dash if it's at the start of a sentence\n",
    "        sentence = re.sub(r'\\s*-\\s+', ' ', sentence)  # Remove \" - \" pattern\n",
    "        sentence = re.sub(r'^\\s*-\\s+', '', sentence)  # Remove dash at beginning of text\n",
    "        sentence = re.sub(r'\\n\\s*-\\s+', '\\n', sentence)  # Remove dash at beginning of lines\n",
    "        sentence = re.sub(r'^\\s*—\\s+', '', sentence)  # Remove dash at beginning of text\n",
    "        sentence = re.sub(r'\\n\\s*—\\s+', '\\n', sentence)  # Remove dash at beginning of lines\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "\n",
    "        if sentence.startswith(\",\"):\n",
    "            if merged_sentences:\n",
    "                merged_sentences[-1] += \" \" + sentence  # Merge with the previous sentence\n",
    "            else:\n",
    "                merged_sentences.append(sentence)  # Edge case: if it's the first sentence\n",
    "        else:\n",
    "            merged_sentences.append(sentence)\n",
    "\n",
    "    if buffer:\n",
    "        merged_sentences.append(buffer)  # Add any leftover buffer\n",
    "\n",
    "    return merged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gale_church_align(english_sentences, french_sentences, skip_weight=2.0):\n",
    "    \"\"\"\n",
    "    Aligns English and French sentences using a dynamic programming approach.\n",
    "    \n",
    "    Allowed moves:\n",
    "      (1,1): Align one English sentence with one French sentence.\n",
    "      (1,0): Skip a French sentence (i.e. align an English sentence alone).\n",
    "      (0,1): Skip an English sentence (i.e. align a French sentence alone).\n",
    "      \n",
    "    The cost for a 1:1 alignment is the absolute difference in word counts.\n",
    "    The skip cost is the sentence's word count multiplied by skip_weight.\n",
    "    \n",
    "    A heavy penalty is applied on the very first skip move to force the first \n",
    "    English and French sentences to be aligned.\n",
    "    \n",
    "    Returns a list of aligned blocks (pairs). Note that these blocks may contain\n",
    "    multiple sentences from each side (i.e. merged blocks), but increasing skip_weight\n",
    "    will tend to force a more granular (less merged) alignment.\n",
    "    \"\"\"\n",
    "    eng_len = len(english_sentences)\n",
    "    fr_len = len(french_sentences)\n",
    "    \n",
    "    # Compute sentence lengths (word counts)\n",
    "    eng_lengths = np.array([len(sent.split()) for sent in english_sentences])\n",
    "    fr_lengths = np.array([len(sent.split()) for sent in french_sentences])\n",
    "    \n",
    "    # Build a cost matrix based on absolute differences in word counts\n",
    "    cost_matrix = np.abs(eng_lengths[:, None] - fr_lengths[None, :])\n",
    "    \n",
    "    # Initialize DP and backtrace tables.\n",
    "    dp = np.full((eng_len+1, fr_len+1), float('inf'))\n",
    "    backtrace = np.zeros((eng_len+1, fr_len+1), dtype=int)\n",
    "    dp[0,0] = 0\n",
    "    \n",
    "    # --- Boundary Initialization with heavy penalty on first skip ---\n",
    "    for i in range(1, eng_len+1):\n",
    "        if i == 1:\n",
    "            dp[i, 0] = dp[i-1, 0] + 1000 * eng_lengths[i-1]  # heavy penalty\n",
    "        else:\n",
    "            dp[i, 0] = dp[i-1, 0] + skip_weight * eng_lengths[i-1]\n",
    "        backtrace[i,0] = 2  # (1,0) move\n",
    "    for j in range(1, fr_len+1):\n",
    "        if j == 1:\n",
    "            dp[0, j] = dp[0, j-1] + 1000 * fr_lengths[j-1]  # heavy penalty\n",
    "        else:\n",
    "            dp[0, j] = dp[0, j-1] + skip_weight * fr_lengths[j-1]\n",
    "        backtrace[0,j] = 3  # (0,1) move\n",
    "    # --- End Boundary Initialization ---\n",
    "    \n",
    "    # Fill DP table for i>=1 and j>=1.\n",
    "    for i in range(1, eng_len+1):\n",
    "        for j in range(1, fr_len+1):\n",
    "            # Option 1: (1,1) alignment.\n",
    "            cost_11 = cost_matrix[i-1, j-1]\n",
    "            if dp[i-1, j-1] + cost_11 < dp[i,j]:\n",
    "                dp[i,j] = dp[i-1,j-1] + cost_11\n",
    "                backtrace[i,j] = 1\n",
    "            # Option 2: (1,0) skip French.\n",
    "            cost_10 = skip_weight * eng_lengths[i-1]\n",
    "            if dp[i-1, j] + cost_10 < dp[i,j]:\n",
    "                dp[i,j] = dp[i-1, j] + cost_10\n",
    "                backtrace[i,j] = 2\n",
    "            # Option 3: (0,1) skip English.\n",
    "            cost_01 = skip_weight * fr_lengths[j-1]\n",
    "            if dp[i, j-1] + cost_01 < dp[i,j]:\n",
    "                dp[i,j] = dp[i, j-1] + cost_01\n",
    "                backtrace[i,j] = 3\n",
    "    \n",
    "    # Backtrace to reconstruct the alignment.\n",
    "    aligned_blocks = []\n",
    "    i, j = eng_len, fr_len\n",
    "    eng_buffer, fr_buffer = [], []\n",
    "    \n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and backtrace[i,j] == 1:\n",
    "            # (1,1) move: flush buffers.\n",
    "            eng_buffer.append(english_sentences[i-1])\n",
    "            fr_buffer.append(french_sentences[j-1])\n",
    "            aligned_blocks.append((\" \".join(reversed(eng_buffer)),\n",
    "                                     \" \".join(reversed(fr_buffer))))\n",
    "            eng_buffer, fr_buffer = [], []\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and (j == 0 or backtrace[i,j] == 2):\n",
    "            # (1,0): Skip French.\n",
    "            eng_buffer.append(english_sentences[i-1])\n",
    "            i -= 1\n",
    "        elif j > 0 and (i == 0 or backtrace[i,j] == 3):\n",
    "            # (0,1): Skip English.\n",
    "            fr_buffer.append(french_sentences[j-1])\n",
    "            j -= 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # If any leftover sentences remain, add them as one block.\n",
    "    if eng_buffer or fr_buffer:\n",
    "        aligned_blocks.insert(0, (\" \".join(reversed(eng_buffer)),\n",
    "                                    \" \".join(reversed(fr_buffer))))\n",
    "    \n",
    "    # Reverse the blocks to restore original order.\n",
    "    aligned_blocks.reverse()\n",
    "    # Remove any completely empty blocks.\n",
    "    aligned_blocks = [(e, f) for e, f in aligned_blocks if e.strip() or f.strip()]\n",
    "    return aligned_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working version \n",
    "\n",
    "def gale_church_align(english_sentences, french_sentences, merge_threshold=5):\n",
    "    \"\"\"\n",
    "    Aligns English and French sentences using a dynamic programming approach.\n",
    "    \n",
    "    This version uses three moves:\n",
    "      (1,1): Align one English sentence with one French sentence.\n",
    "      (1,0): Skip a French sentence (i.e. align an English sentence alone).\n",
    "      (0,1): Skip an English sentence (i.e. align a French sentence alone).\n",
    "      \n",
    "    A heavy penalty is applied on the very first skip move to force the first\n",
    "    sentences on both sides to align.\n",
    "    \n",
    "    Returns a list of aligned pairs (blocks). Each block may contain multiple \n",
    "    sentences from each language; the sum of sentences across blocks equals the \n",
    "    original counts.\n",
    "    \"\"\"\n",
    "    eng_len = len(english_sentences)\n",
    "    fr_len = len(french_sentences)\n",
    "\n",
    "    # Compute sentence lengths (using word counts)\n",
    "    eng_lengths = np.array([len(sent.split()) for sent in english_sentences])\n",
    "    fr_lengths = np.array([len(sent.split()) for sent in french_sentences])\n",
    "    \n",
    "    # Create a cost matrix based on absolute differences in word counts\n",
    "    cost_matrix = np.abs(eng_lengths[:, None] - fr_lengths[None, :])\n",
    "    \n",
    "    # Initialize DP table and backtrace table\n",
    "    dp = np.full((eng_len + 1, fr_len + 1), float('inf'))\n",
    "    backtrace = np.zeros((eng_len + 1, fr_len + 1), dtype=int)\n",
    "    dp[0, 0] = 0\n",
    "\n",
    "    # --- Boundary Initialization with heavy penalty on first skip ---\n",
    "    for i in range(1, eng_len + 1):\n",
    "        if i == 1:\n",
    "            # Heavy penalty for skipping the first English sentence\n",
    "            dp[i, 0] = dp[i - 1, 0] + 1000 * eng_lengths[i - 1]\n",
    "        else:\n",
    "            dp[i, 0] = dp[i - 1, 0] + eng_lengths[i - 1]\n",
    "        backtrace[i, 0] = 2  # Move: (1,0)\n",
    "    for j in range(1, fr_len + 1):\n",
    "        if j == 1:\n",
    "            # Heavy penalty for skipping the first French sentence\n",
    "            dp[0, j] = dp[0, j - 1] + 1000 * fr_lengths[j - 1]\n",
    "        else:\n",
    "            dp[0, j] = dp[0, j - 1] + fr_lengths[j - 1]\n",
    "        backtrace[0, j] = 3  # Move: (0,1)\n",
    "    # --- End Boundary Initialization ---\n",
    "\n",
    "    # Fill DP table for cells (i>=1, j>=1)\n",
    "    for i in range(1, eng_len + 1):\n",
    "        for j in range(1, fr_len + 1):\n",
    "            # Option 1: Align one English sentence with one French sentence (1,1)\n",
    "            cost = cost_matrix[i - 1, j - 1]\n",
    "            if dp[i - 1, j - 1] + cost < dp[i, j]:\n",
    "                dp[i, j] = dp[i - 1, j - 1] + cost\n",
    "                backtrace[i, j] = 1  # (1,1)\n",
    "            # Option 2: Skip French sentence (merge English sentence)\n",
    "            cost = cost_matrix[i - 1, j - 1]\n",
    "            if dp[i - 1, j] + cost < dp[i, j]:\n",
    "                dp[i, j] = dp[i - 1, j] + cost\n",
    "                backtrace[i, j] = 2  # (1,0)\n",
    "            # Option 3: Skip English sentence (merge French sentence)\n",
    "            cost = cost_matrix[i - 1, j - 1]\n",
    "            if dp[i, j - 1] + cost < dp[i, j]:\n",
    "                dp[i, j] = dp[i, j - 1] + cost\n",
    "                backtrace[i, j] = 3  # (0,1)\n",
    "\n",
    "    # Backtrace to reconstruct aligned blocks\n",
    "    aligned_sentences = []\n",
    "    i, j = eng_len, fr_len\n",
    "    eng_buffer, fr_buffer = [], []\n",
    "    \n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and backtrace[i, j] == 1:\n",
    "            # (1,1): Align both; flush buffers into a block\n",
    "            eng_buffer.append(english_sentences[i - 1])\n",
    "            fr_buffer.append(french_sentences[j - 1])\n",
    "            aligned_sentences.append((\" \".join(reversed(eng_buffer)),\n",
    "                                      \" \".join(reversed(fr_buffer))))\n",
    "            eng_buffer, fr_buffer = [], []\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and (j == 0 or backtrace[i, j] == 2):\n",
    "            # (1,0): Skip French, accumulate English sentence.\n",
    "            eng_buffer.append(english_sentences[i - 1])\n",
    "            i -= 1\n",
    "        elif j > 0 and (i == 0 or backtrace[i, j] == 3):\n",
    "            # (0,1): Skip English, accumulate French sentence\n",
    "            fr_buffer.append(french_sentences[j - 1])\n",
    "            j -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # If any leftover sentences remain, add them as one block\n",
    "    if eng_buffer or fr_buffer:\n",
    "        aligned_sentences.insert(0, (\" \".join(reversed(eng_buffer)),\n",
    "                                       \" \".join(reversed(fr_buffer))))\n",
    "\n",
    "    # Reverse the aligned blocks to restore original order\n",
    "    aligned_sentences.reverse()\n",
    "    \n",
    "    # Remove any completely empty blocks\n",
    "    aligned_sentences = [(e, f) for e, f in aligned_sentences if e.strip() or f.strip()]\n",
    "    return aligned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_align(english_input, french_input, english_output, french_output, merge_threshold=50):\n",
    "    \n",
    "    with open(english_input, 'r', encoding='utf-8') as eng_in, \\\n",
    "         open(french_input, 'r', encoding='utf-8') as fr_in:\n",
    "        \n",
    "        english_text = ' '.join([line.strip() for line in eng_in if line.strip()])\n",
    "        french_text = ' '.join([line.strip() for line in fr_in if line.strip()]) \n",
    "\n",
    "        english_text = clean_text(english_text)\n",
    "        french_text = clean_text(french_text)\n",
    "\n",
    "        english_sentences = split_into_sentences(english_text)\n",
    "        french_sentences = split_into_sentences(french_text)\n",
    "\n",
    "    print(f\"Initial sentence count: English ({len(english_sentences)}), French ({len(french_sentences)})\")\n",
    "    aligned_sentences = gale_church_align(english_sentences, french_sentences)\n",
    "\n",
    "    num_aligned = len(aligned_sentences)\n",
    "    print(f\"Aligned sentence count: {num_aligned}\")\n",
    "    \n",
    "    # Check if there's a mismatch\n",
    "    eng_count = sum(1 for eng, _ in aligned_sentences if eng.strip())\n",
    "    fr_count = sum(1 for _, fr in aligned_sentences if fr.strip())\n",
    "\n",
    "    if eng_count != fr_count:\n",
    "        print(f\"Sentence mismatch after alignment! EN = {eng_count}, FR = {fr_count}\")\n",
    "        \n",
    "    with open(english_output, 'w', encoding='utf-8') as eng_out, \\\n",
    "         open(french_output, 'w', encoding='utf-8') as fr_out:\n",
    "        \n",
    "        for eng_sentence, fr_sentence in aligned_sentences:\n",
    "            eng_out.write(eng_sentence.strip() + '\\n')\n",
    "            fr_out.write(fr_sentence.strip() + '\\n')\n",
    "\n",
    "    print(f\"✅ Complete: English file: {english_output}, French file: {french_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sentence count: English (9621), French (9493)\n",
      "Aligned sentence count: 7367\n",
      "✅ Complete: English file: Fr_1854_Lesbazeilles_Souvestre.e, French file: Fr_1854_Lesbazeilles_Souvestre.f\n",
      "Initial sentence count: English (9621), French (25680)\n",
      "Aligned sentence count: 8364\n",
      "✅ Complete: English file: Fr_1919_Gilbert_Duvivier.e, French file: Fr_1919_Gilbert_Duvivier.f\n",
      "Initial sentence count: English (9621), French (9829)\n",
      "Aligned sentence count: 7458\n",
      "✅ Complete: English file: Fr_1946_Redon_Dulong.e, French file: Fr_1946_Redon_Dulong.f\n",
      "Initial sentence count: English (9621), French (10469)\n",
      "Aligned sentence count: 8715\n",
      "✅ Complete: English file: Fr_1964_Maurat.e, French file: Fr_1964_Maurat.f\n",
      "Initial sentence count: English (9621), French (9940)\n",
      "Aligned sentence count: 9180\n",
      "✅ Complete: English file: Fr_1966_Monod.e, French file: Fr_1966_Monod.f\n",
      "Initial sentence count: English (9621), French (13488)\n",
      "Aligned sentence count: 8600\n",
      "✅ Complete: English file: Fr_2008_Jean.e, French file: Fr_2008_Jean.f\n"
     ]
    }
   ],
   "source": [
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_1854_Lesbazeilles_Souvestre.txt', 'Fr_1854_Lesbazeilles_Souvestre.e','Fr_1854_Lesbazeilles_Souvestre.f')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_1919_Gilbert_Duvivier.txt', 'Fr_1919_Gilbert_Duvivier.e','Fr_1919_Gilbert_Duvivier.f')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_1946_Redon_Dulong.txt', 'Fr_1946_Redon_Dulong.e','Fr_1946_Redon_Dulong.f')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_1964_Maurat.txt', 'Fr_1964_Maurat.e','Fr_1964_Maurat.f')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_1966_Monod.txt', 'Fr_1966_Monod.e','Fr_1966_Monod.f')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/Fr_2008_Jean.txt', 'Fr_2008_Jean.e','Fr_2008_Jean.f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sentence count: English (9621), French (9577)\n",
      "Aligned sentence count: 7288\n",
      "✅ Complete: English file: Italian/It_1904_Anon.e, French file: Italian/It_1904_Anon.i\n"
     ]
    }
   ],
   "source": [
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_1904_Anon.txt', 'Italian/It_1904_Anon.e','Italian/It_1904_Anon.i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sentence count: English (9621), French (10308)\n",
      "Aligned sentence count: 8385\n",
      "✅ Complete: English file: It_1951_Pozzo_Galeazzi.e, French file: It_1951_Pozzo_Galeazzi.i\n",
      "Initial sentence count: English (9621), French (12215)\n",
      "Aligned sentence count: 7948\n",
      "✅ Complete: English file: It_1956_SpaventaFilippi.e, French file: It_1956_SpaventaFilippi.i\n",
      "Initial sentence count: English (9621), French (10676)\n",
      "Aligned sentence count: 8732\n",
      "✅ Complete: English file: It_1974_Dettore.e, French file: It_1974_Dettore.i\n",
      "Initial sentence count: English (9621), French (12537)\n",
      "Aligned sentence count: 8076\n",
      "✅ Complete: English file: It_2008_Lamberti.e, French file: It_2008_Lamberti.i\n",
      "Initial sentence count: English (9621), French (12710)\n",
      "Aligned sentence count: 8438\n",
      "✅ Complete: English file: It_2011_DEzio.e, French file: It_2011_DEzio.i\n",
      "Initial sentence count: English (9621), French (11065)\n",
      "Aligned sentence count: 8906\n",
      "✅ Complete: English file: It_2014_Pareschi.e, French file: It_2014_Pareschi.i\n",
      "Initial sentence count: English (9621), French (12503)\n",
      "Aligned sentence count: 8729\n",
      "✅ Complete: English file: It_2014_Sacchini.e, French file: It_2014_Sacchini.i\n"
     ]
    }
   ],
   "source": [
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_1951_Pozzo_Galeazzi.txt', 'It_1951_Pozzo_Galeazzi.e','It_1951_Pozzo_Galeazzi.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_1956_SpaventaFilippi.txt', 'It_1956_SpaventaFilippi.e','It_1956_SpaventaFilippi.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_1974_Dettore.txt', 'It_1974_Dettore.e','It_1974_Dettore.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_2008_Lamberti.txt', 'It_2008_Lamberti.e','It_2008_Lamberti.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_2011_DEzio.txt', 'It_2011_DEzio.e','It_2011_DEzio.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_2014_Pareschi.txt', 'It_2014_Pareschi.e','It_2014_Pareschi.i')\n",
    "process_and_align('full_texts/English_gutenburg.txt', 'full_texts/It_2014_Sacchini.txt', 'It_2014_Sacchini.e','It_2014_Sacchini.i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_texts(folder_path, output_file):\n",
    "#     files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".txt\")])\n",
    "\n",
    "#     with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "#         for i, f in enumerate(files, start=1): \n",
    "#             file_path = os.path.join(folder_path, f)\n",
    "#             with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "#                 text = (infile.read())\n",
    "#                 outfile.write(f\"Capitúlo {i}\\n\\n{text.strip()}\\n\\n\")\n",
    "\n",
    "#     print(f\"Combined text saved to {output_file}\")\n",
    "#     return output_file\n",
    "\n",
    "# combine_texts('original_texts/Spanish_1928_anon', 'full_texts/Spanish_1928_anon.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'aligned-ch1.e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m zip_longest\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load English and French files\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maligned-ch1.e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m eng_file:\n\u001b[1;32m      5\u001b[0m     english_sentences \u001b[38;5;241m=\u001b[39m eng_file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maligned-ch1.f\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fr_file:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aligned-ch1.e'"
     ]
    }
   ],
   "source": [
    "# # manual alignment\n",
    "# from itertools import zip_longest\n",
    "\n",
    "# # Load English and French files\n",
    "# with open('aligned-ch1.e', 'r', encoding='utf-8') as eng_file:\n",
    "#     english_sentences = eng_file.readlines()\n",
    "\n",
    "# with open('aligned-ch1.f', 'r', encoding='utf-8') as fr_file:\n",
    "#     french_sentences = fr_file.readlines()\n",
    "\n",
    "# # Compare sentences line by line\n",
    "# for idx, (eng_sent, fr_sent) in enumerate(zip_longest(english_sentences, french_sentences, fillvalue='')):\n",
    "#     eng_sent = eng_sent.strip()\n",
    "#     fr_sent = fr_sent.strip()\n",
    "#     eng_len = len(eng_sent)\n",
    "#     fr_len = len(fr_sent)\n",
    "\n",
    "#     # Check for significant difference (e.g., one is 1.5x longer)\n",
    "#     if fr_len > 1.5 * eng_len:\n",
    "#         status = \"⚠️ French significantly longer\"\n",
    "#     elif eng_len > 1.5 * fr_len:\n",
    "#         status = \"⚠️ English significantly longer\"\n",
    "#     elif fr_len == eng_len == 0: \n",
    "#         continue\n",
    "#     else:\n",
    "#         status = \"✅ Aligned\"\n",
    "\n",
    "#     # Display the comparison\n",
    "#     print(f\"Line {idx + 1}: {status}\")\n",
    "#     print(f\"EN: {eng_sent}\")\n",
    "#     print(f\"FR: {fr_sent}\")\n",
    "#     print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
